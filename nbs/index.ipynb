{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clip-video-classifier\n",
    "\n",
    "> assignment repo for video classification of ssbd dataset using CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "git clone https://github.com/sizhky/ssbd\n",
    "cd ssbd\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use\n",
    "```bash\n",
    "clip-video-classifier --help\n",
    "clip-video-classifier COMMAND --help\n",
    "```\n",
    "to see help for all commands\n",
    "\n",
    "---\n",
    "To train a transformer model on SSBD videos using CLIP as feature extractor\n",
    "\n",
    "1. First setup your annotations\n",
    "```bash\n",
    "DATA_DIR=\"/mnt/347832F37832B388/ml-datasets/ssbd\"\n",
    "RAW_VIDEO_DIR=\"$DATA_DIR/ssbd-raw-videos\"\n",
    "clip-video-classifier setup-annotations $DATA_DIR\n",
    "clip-video-classifier download-raw-videos $DATA_DIR/annotations.csv $RAW_VIDEO_DIR\n",
    "clip-video-classifier setup-annotations $DATA_DIR --fill-gaps --videos-folder $RAW_VIDEO_DIR\n",
    "```\n",
    "\n",
    "2. Next extract frames for each video\n",
    "```bash\n",
    "# change the num-frames-per-sec in the below script if needed\n",
    "$ chmod +x scripts/extract_frames.sh\n",
    "$ ./extract_frames.sh\n",
    "```\n",
    "\n",
    "3. Now extract embeddings for each `frames.tensor` file saved\n",
    "```bash\n",
    "clip-video-classifier frames-to-embeddings \"/mnt/347832F37832B388/ml-datasets/ssbd/ssbd-frames/5fps\" \"/mnt/347832F37832B388/ml-datasets/ssbd/ssbd-embeddings/5fps\" \"ViT-B/32\" \"cuda\"\n",
    "```\n",
    "\n",
    "4. Finally you can run the notebook `nbs/models/02_transformer_clip.ipynb` by pointing to the approprirate ssbd-embeddings folder and setting the right hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly run the notebook `nbs/model/03_infer.ipynb` to load the deeplearning model and make predictions on every 5 second intervals\n",
    "\n",
    "or \n",
    "\n",
    "You can launch a fastapi server `uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload` and send a post request like so\n",
    "\n",
    "<img src='https://i.imgur.com/n02QPzW.png' alt='image' height='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
