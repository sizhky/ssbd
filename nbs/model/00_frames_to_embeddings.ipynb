{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Embeddings\n",
    "\n",
    "> Given a folder of frames, export their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp models.frame_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%reload_ext nb_black\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "\n",
    "__root = \"../../\"\n",
    "sys.path.append(__root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from clip_video_classifier.cli import cli\n",
    "from torch_snippets import *\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Frame2Embeddings:\n",
    "    def __init__(self, model=\"ViT-B/32\", device=\"cuda\", batch_size=16):\n",
    "        self.model, self.preprocess = clip.load(model, device=device)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(self, frames_tensor_path_or_folder, **kwargs):\n",
    "        if os.path.isdir(frames_tensor_path_or_folder):\n",
    "            return self.extract_clip_embeddings_for_folder(\n",
    "                frames_tensor_path_or_folder, **kwargs\n",
    "            )\n",
    "        else:\n",
    "            return self.frames2clip_image_embeddings(\n",
    "                frames_tensor_path_or_folder, **kwargs\n",
    "            )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def frames2clip_image_embeddings(self, frames_tensor_path):\n",
    "        frames = loaddill(frames_tensor_path)\n",
    "        frames = [\n",
    "            (np.array(a) * 255).astype(np.uint8).transpose(1, 2, 0) for a in frames\n",
    "        ]\n",
    "        frames = [Image.fromarray(im) for im in frames]\n",
    "        frames = torch.stack([self.preprocess(im) for im in frames]).to(device)\n",
    "        batches = torch.split(frames, self.batch_size)\n",
    "        embeddings = []\n",
    "        for batch in batches:\n",
    "            embeddings.append(self.model.encode_image(batch).cpu().detach())\n",
    "        embeddings = torch.cat(embeddings)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def extract_clip_embeddings_for_folder(\n",
    "        self, frames_folder, embeddings_folder, n=None\n",
    "    ):\n",
    "        frames_folder = P(frames_folder)\n",
    "        embeddings_folder = P(embeddings_folder)\n",
    "        makedir(embeddings_folder)\n",
    "        for ix, frames_tensor_path in E((tracker := track2(frames_folder.ls()))):\n",
    "            tracker.send(f\"Processing {frames_tensor_path}\")\n",
    "            if n is not None and ix >= n:\n",
    "                return\n",
    "            to = f\"{embeddings_folder}/{stem(frames_tensor_path)}.embeddings.tensor\"\n",
    "            if exists(to):\n",
    "                Info(f\"Skipping {to} as it already exists\")\n",
    "                continue\n",
    "            embeddings = self(frames_tensor_path)\n",
    "            dumpdill(embeddings, to)\n",
    "\n",
    "\n",
    "@cli.command()\n",
    "def frames_to_embeddings(frames_folder, embeddings_folder, model, device):\n",
    "    f2e = Frame2Embeddings(model, device)\n",
    "    f2e(frames_folder, embeddings_folder=embeddings_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the object\n",
    "```python\n",
    "root = P(\"/mnt/347832F37832B388/ml-datasets/ssbd/\")\n",
    "f2e = Frame2Embeddings()\n",
    "```\n",
    "\n",
    "Usage for a single set of frames\n",
    "```python\n",
    "frames_folder = root / \"ssbd-frames/10fps\"\n",
    "frames_path = frames_folder.ls()[0]\n",
    "frames = loaddill(frames_path)\n",
    "subplots(frames)\n",
    "f2e(frames_path)\n",
    "```\n",
    "---\n",
    "Usage for a folder of frames\n",
    "```python\n",
    "embeddings_folder = root/\"ssbd-embeddings/10fps\"\n",
    "f2e(frames_folder, embeddings_folder=embeddings_folder, n=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcvp-book",
   "language": "python",
   "name": "mcvp-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
