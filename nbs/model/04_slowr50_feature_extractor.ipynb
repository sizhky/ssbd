{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer using a Transformer\n",
    "\n",
    "> Module for training on a dataset of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext nb_black\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "\n",
    "__root = \"../../\"\n",
    "sys.path.append(__root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    UniformCropVideo,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 64\n",
    "# sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "alpha = 4\n",
    "\n",
    "# model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)\n",
    "transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x / 255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(size=side_size),\n",
    "            CenterCropVideo(crop_size=(crop_size, crop_size)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "\n",
    "root = P(\"/mnt/347832F37832B388/ml-datasets/ssbd\")\n",
    "annotations = pd.read_csv(f\"{root}/annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 32\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "alpha = 4\n",
    "\n",
    "model = torch.hub.load(\"facebookresearch/pytorchvideo\", \"slow_r50\", pretrained=True)\n",
    "\n",
    "transform = lambda num_frames=num_frames: ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x / 255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(size=side_size),\n",
    "            CenterCropVideo(crop_size=(crop_size, crop_size)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = choose(annotations.query(\"start == 3 and end == 7\"))\n",
    "show(row.to_frame().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model from Hub\n",
    "\n",
    "```python\n",
    "model = torch.hub.load(\n",
    "    \"facebookresearch/pytorchvideo\", \"slow_r50\", pretrained=True\n",
    ").cuda()\n",
    "\n",
    "import json\n",
    "with open(\"kinetics_classnames.json\", \"r\") as f:\n",
    "    kinetics_classnames = json.load(f)\n",
    "kinetics_id_to_classname = {}\n",
    "for k, v in kinetics_classnames.items():\n",
    "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")\n",
    "```\n",
    "\n",
    "```python\n",
    "raw_videos_folder = root / \"ssbd-raw-videos\"\n",
    "video = EncodedVideo.from_path(raw_videos_folder / f\"{row.video}.mp4\")\n",
    "video_data = video.get_clip(start_sec=row.start, end_sec=row.end)\n",
    "Info(video_data)\n",
    "video_data = transform()(video_data)\n",
    "# num_frames = (row.end - row.start) * 10\n",
    "# video_data = transform_num_frames(num_frames)(video_data)\n",
    "Info(video_data)\n",
    "inputs = video_data[\"video\"][None]\n",
    "Info(inputs)\n",
    "# Generate top 5 predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(inputs.cuda())\n",
    "\n",
    "preds = torch.nn.functional.softmax(preds, dim=-1)\n",
    "print(preds)\n",
    "pred_class_ids = preds.topk(k=5).indices\n",
    "\n",
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_class_ids[0]]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
    "```\n",
    "---\n",
    "\n",
    "```python\n",
    "frames_folder = root / \"ssbd-frames/10fps\"\n",
    "\n",
    "mean_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(size=side_size),\n",
    "            CenterCropVideo(crop_size=(crop_size, crop_size)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "for frames_path in Glob(frames_folder):\n",
    "    frames = {\"video\": loaddill(frames_path).permute(1, 0, 2, 3)}\n",
    "    # frames = {\"video\": loaddill(frames_folder / \"198.frames.tensor\").permute(1, 0, 2, 3)}\n",
    "    Info(frames)\n",
    "    frames = mean_transform(frames)[\"video\"][None]\n",
    "    Info(frames)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(frames.cuda())\n",
    "\n",
    "    preds = torch.nn.functional.softmax(preds, dim=-1)\n",
    "    print(preds)\n",
    "    pred_class_ids = preds.topk(k=5).indices\n",
    "\n",
    "    pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_class_ids[0]]\n",
    "    print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folder = root / \"ssbd-frames/10fps\"\n",
    "\n",
    "mean_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            NormalizeVideo(mean, std),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "feature_extractor = nn.Sequential(*model.blocks[:4]).cpu()\n",
    "features_folder = root / \"ssbd-frames-features/10fps/slow_r50/\"\n",
    "makedir(features_folder)\n",
    "\n",
    "for frames_path in (tracker := track2(Glob(frames_folder))):\n",
    "    item = stem(frames_path)\n",
    "    if item in [\"477.frames\", \"407.frames\"]:\n",
    "        continue\n",
    "    to = features_folder / f\"{item}.features.tensor\"\n",
    "    if exists(to):\n",
    "        continue\n",
    "    frames = loaddill(frames_path).permute(1, 0, 2, 3)\n",
    "    frames = {\"video\": frames}\n",
    "    frames = mean_transform(frames)[\"video\"][None]\n",
    "    tracker.send(f\"processing {item} @ {frames}\")\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            preds = feature_extractor(frames.cpu()).cpu()\n",
    "            dumpdill(preds, to, silent=True)\n",
    "        except Exception as e:\n",
    "            Warn(f\"{e} @ {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcvp-book",
   "language": "python",
   "name": "mcvp-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
